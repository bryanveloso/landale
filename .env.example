# Copy this file to .env and fill in your values

# Database (set by docker-compose for containers)
DATABASE_URL=postgres://landale:landale@localhost:5433/landale

# Cloak encryption key (required for production)
# Generate with: mix phx.gen.secret 32 | xargs -I {} echo -n {} | base64
CLOAK_SECRET_KEY=your_base64_encoded_key_here

# Twitch API Configuration
TWITCH_CLIENT_ID=your_twitch_client_id
TWITCH_CLIENT_SECRET=your_twitch_client_secret
TWITCH_EVENTSUB_SECRET="your_eventsub_secret"
TWITCH_USER_ID=your_twitch_user_id

# Whisper Configuration (optional)
WHISPER_CPP_PATH=/Users/Avalonstar/Code/utilities/whisper.cpp/build/bin/whisper-cli
WHISPER_MODEL_PATH=/Users/Avalonstar/Code/utilities/whisper.cpp/models/ggml-large-v3-turbo-q8_0.bin
WHISPER_VAD_MODEL_PATH=/Users/Avalonstar/Code/utilities/whisper.cpp/models/ggml-silero-v5.1.2.bin

# LM Studio Configuration (optional)
LMS_API_URL=http://localhost:1234/v1
LMS_MODEL=local-model
LMS_CONTEXT_WINDOW=10
LMS_SYSTEM_PROMPT="You are an AI assistant monitoring a live stream. Analyze recent transcriptions and identify interesting moments, topics, or patterns. Be concise and highlight only significant observations."

# Seq Logging (optional)
# SEQ_HOST=saya.tail-scale.ts.net
# SEQ_PORT=5341
# SEQ_API_KEY=

# Service Host Overrides (optional)
# Override the default hosts from services.json
# SERVER_HOST=saya
# OBS_HOST=demi
# PHONONMASER_HOST=zelan

# Python Service Configuration (simplified for personal use)
# Most settings are fixed - only configure what you need to change
SERVER_HOST=localhost
LOG_LEVEL=INFO

# LM Studio Configuration (for Seed)
LMS_HOST=localhost
LMS_PORT=1234
LMS_MODEL=local-model

# OBS WebSocket Configuration
OBS_WEBSOCKET_URL=ws://100.106.173.14:4455
